{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RED NEURONAL PREDICTORA\n",
    "\n",
    "En este notebook se podrá visualizar el codigo relacionado con el aprendizaje no supervisado unicamente. Para visualizar el codigo relacionado con el aprendizaje supervisado acceder al archivo de este mismo repositorio: red_neuronal_predictora.ipynb (para la red neuronal predictora), arbol_decisión.ipynb (para el arbol de decisión) o red_neuronal_hiperparametros.ipynb (para la el ajuste de hiperparametros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de las librerías \n",
    "\n",
    "A continuación se importan las librerias necesarias. Adicionalmente se configuran unas variables de entorno para obtener los mismos resultados para las diferentes ejecuciones. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar los datos\n",
    "\n",
    "El primer paso es cargar el dataset adecuadamente. Recordemos que el archivo csv esta preprocesado con antelación y al estar en el aprendizaje no supervisado las columnas \"ID Usuario\" y la etiqueta \"Conclusion\" se prescinde de ellas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos desde el archivo CSV\n",
    "file_path = 'supervisado_final.csv'  # Archivo CSV\n",
    "data = pd.read_csv(file_path, sep=';', decimal='.')\n",
    "\n",
    "# Seleccionar todas las columnas excepto la primera ('ID Usuario') y la última (la etiqueta)\n",
    "features = data.iloc[:, 1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "En este apartado se podrán visualizar los diferentes resultados obtenidos para un numero de cluster modificable, el actual K = 3, el que mejores resultados ofrece trás el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias especificas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de clusters, K\n",
    "num_clusters = 3\n",
    "\n",
    "# Aplicar K-means con k=3 y calcular la métrica Silhouette\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "clusters = kmeans.fit_predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de la metrica Silhouette:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(features, clusters)\n",
    "print(f'\\n\\n\\nSilhouette score for {num_clusters} clusters: {silhouette_avg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Añadir al dataset los clusters asignados e imprimir la cantidad de trabajadores por cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadir el cluster asignado a cada observación\n",
    "data['Cluster'] = clusters\n",
    "\n",
    "# Contar el número de ítems en cada cluster\n",
    "cluster_counts = data['Cluster'].value_counts().sort_index()\n",
    "\n",
    "# Imprimir el número de ítems en cada cluster\n",
    "print(\"\\n\\n\\nNúmero de ítems en cada cluster:\")\n",
    "print(cluster_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se calcula la media de cada variable/columna para todos los clusers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media de cada columna en cada cluster\n",
    "cluster_means = data.groupby('Cluster').mean()\n",
    "\n",
    "# Eliminar las columnas de ID Usuario y de Conclusion\n",
    "cluster_means = cluster_means.drop(['ID Usuario', 'Conclusion'], axis=1)\n",
    "\n",
    "# Imprimir la media de cada columna en cada cluster\n",
    "print(\"\\n\\n\\nMedia de cada columna en cada cluster:\")\n",
    "print(cluster_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular el ranking de la \"separabilidad de variables\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar todas las combinaciones de pares de clusters\n",
    "cluster_pairs = list(combinations(range(num_clusters), 2))\n",
    "\n",
    "# Calcular la diferencia total entre clusters para cada variable de forma genérica\n",
    "total_diff = sum(np.abs(cluster_means.loc[pair[0]] - cluster_means.loc[pair[1]]) for pair in cluster_pairs) / len(cluster_pairs)\n",
    "\n",
    "# Ordenar las variables según la diferencia total entre clusters de forma descendente\n",
    "ordered_columns = total_diff.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar tanto en consola como en un diagrama de barras los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimir las columnas ordenadas\n",
    "print(\"\\n\\n\\nColumnas ordenadas según la diferencia total entre clusters:\")\n",
    "print(ordered_columns)\n",
    "\n",
    "# Crear el diagrama de barras\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.bar(ordered_columns.index, ordered_columns.values)\n",
    "\n",
    "# Añadir etiquetas y título\n",
    "plt.xlabel('Variables')\n",
    "plt.ylabel('Diferencia total entre clusters')\n",
    "plt.title('Variables ordenadas según la diferencia total entre clusters')\n",
    "\n",
    "# Rotar las etiquetas del eje x para que sean legibles\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Mostrar el diagrama de barras\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionamos las variables que superen el umbral 0.24 siendo este umbral la linea de división analizada. Imprimimos las medias de esas variables seleccionadas para todos los clusters para una mayor legibilidad y posterior comparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar solo las columnas que superen un umbral de 0.24\n",
    "selected_columns = ordered_columns[ordered_columns > 0.24]\n",
    "\n",
    "# Imprimir las columnas seleccionadas\n",
    "print(\"\\n\\n\\nColumnas seleccionadas:\")\n",
    "print(selected_columns)\n",
    "\n",
    "# Seleccionar solo las filas correspondientes en el DataFrame cluster_means\n",
    "selected_means = cluster_means.loc[:, selected_columns.index]\n",
    "\n",
    "# Imprimir las medias seleccionadas\n",
    "print(\"\\n\\n\\nMedias seleccionadas:\")\n",
    "print(selected_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reducción de Dimensionalidad\n",
    "\n",
    "En este apartado se obserban dos diferentes metodos de reducción de dimendsionalidad y diferentes caracteristicas de cada una de ellas para la selección de la mejor adaptada al problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Librerias especificas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Obtención de los componentes principales para representar los resultados en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar PCA para obtener las componentes principales\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimir la varianza de las dos primeras componentes principales para saber la información que mantiene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varianza explicada por las dos primeras componentes principales\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"\\n\\n\\nVarianza explicada por la PC1: {explained_variance_ratio[0]:.4f}\")\n",
    "print(f\"\\nVarianza explicada por la PC2: {explained_variance_ratio[1]:.4f}\")\n",
    "print(f\"\\nVarianza total explicada por las dos primeras componentes principales: {explained_variance_ratio[:2].sum():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtención de los componentes principales ordenados por valor absoluto para saber que caracteristicas han sido seleccionadas para la representación en 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las componentes principales ordenadas por valor absoluto\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=['PCA1', 'PCA2'], index=features.columns)\n",
    "sorted_loadings = loadings.abs().sort_values(by=['PCA1', 'PCA2'], ascending=False)\n",
    "print(\"\\n\\n\\nCargas de los componentes principales ordenadas por valor absoluto:\")\n",
    "print(sorted_loadings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluación de la reducción de dimensionalidad para posterior comparación con la varianza obtenida por las dos primeras PCA. Se hace un KNN = 5 (probar con diferentes valores) tanto para los datos originales como para los reducidos por t-SNE y se comparan para saber la consistencia de vecindad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar la preservación de vecindad\n",
    "n_neighbors = 5\n",
    "nn_original = NearestNeighbors(n_neighbors=n_neighbors).fit(features)\n",
    "_, neighbors_original = nn_original.kneighbors(features)\n",
    "nn_tsne = NearestNeighbors(n_neighbors=n_neighbors).fit(tsne_results)\n",
    "_, neighbors_tsne = nn_tsne.kneighbors(tsne_results)\n",
    "\n",
    "# Calcular la consistencia de vecindad\n",
    "consistencies = [len(set(neighbors_original[i]).intersection(set(neighbors_tsne[i]))) / n_neighbors for i in range(features.shape[0])]\n",
    "mean_consistency = np.mean(consistencies)\n",
    "print(f'\\n\\n\\nConsistencia de vecindad media: {mean_consistency:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualización de los clusters utilizando t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los clusters utilizando t-SNE\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=clusters, palette='viridis')\n",
    "plt.title('Clusters visualizados usando t-SNE')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detección de anomalias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
